{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import copy\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import Birch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor = KNN\n",
    "# Isolation forest = random forest\n",
    "# One-Class SVM = SVM\n",
    "# Elliptic Envelope = Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyzer:\n",
    "    def __init__(self, balance_weights = True, algo = \"knn\"):\n",
    "        file_path = 'Taiwanese Bankruptcy Prediction.csv'\n",
    "\n",
    "        self.dataset = pd.read_csv(file_path, header=None)\n",
    "        self.dataset.columns = self.dataset.iloc[0]\n",
    "\n",
    "        self.dataset = self.dataset.drop(0)\n",
    "        self.original_dataset = self.dataset\n",
    "        self.fill_nan_vals()\n",
    "        self.convert_columns()\n",
    "        self.balance_weights = balance_weights\n",
    "        self.algo = algo\n",
    "        self.knn_weight = \"uniform\"\n",
    "        self.class_weight = None\n",
    "        if balance_weights:\n",
    "            self.knn_weight = \"distance\"\n",
    "            self.class_weight = \"balanced\"\n",
    "        print(self.class_weight)\n",
    "\n",
    "    def fill_nan_vals(self):\n",
    "        for column in self.dataset.columns:\n",
    "            if self.dataset[column].dtype == 'object':  # Non-numerical column\n",
    "                mode_val = self.dataset[column].mode()[0]\n",
    "                self.dataset[column] = self.dataset[column].fillna(mode_val)\n",
    "            else:  # Numerical column\n",
    "                mean_val = self.dataset[column].mean()\n",
    "                self.dataset[column] = self.dataset[column].fillna(mean_val)\n",
    "    \n",
    "    def convert_columns(self):\n",
    "        # Convert all columns to float except 'Bankrupt?' and 'Net Income Flag'\n",
    "        for column in self.dataset.columns:\n",
    "            if column not in ['Bankrupt?', 'Net Income Flag']:\n",
    "                self.dataset[column] = self.dataset[column].astype(float)\n",
    "            else:\n",
    "                self.dataset[column] = self.dataset[column].astype(int)\n",
    "\n",
    "    def show_class_distribution(self):\n",
    "        target_column = 'Bankrupt?'\n",
    "        # Load your dataset into a pandas DataFrame\n",
    "\n",
    "        # Step 2: Inspect the Target Variable\n",
    "        class_distribution = self.dataset[target_column].value_counts()\n",
    "\n",
    "        # Step 3: Visualize the Distribution\n",
    "        class_distribution.plot(kind='bar', title='Target Variable Distribution')\n",
    "        print(class_distribution)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "    def show_heat_map(self, dataset = None):\n",
    "        if dataset is None:\n",
    "            corr_matrix = self.dataset.corr()\n",
    "        else:\n",
    "            corr_matrix = dataset.corr()\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_x_and_Y(self):\n",
    "        self.X = self.dataset.drop('Bankrupt?', axis=1)  # Assuming 'p' is the target variable\n",
    "        self.y = self.dataset['Bankrupt?']\n",
    "        return (self.X, self.y)\n",
    "    \n",
    "    def perform_manual_splitting_without_cv(self):\n",
    "        X_train, self.X_test_final, y_train, self.y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "    \n",
    "    def perform_manual_splitting_cv(self):\n",
    "        # First split to get training set and first test set\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(self.X, self.y, test_size=0.4, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_cv, self.X_test_final, self.y_cv, self.y_test_final = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "    \n",
    "    def perform_kfold_cv(self, num_of_columns = None):\n",
    "        X_train, X_test_final, y_train, y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        if num_of_columns:\n",
    "            X_train = copy.deepcopy(X_train.iloc[:, :num_of_columns])\n",
    "            X_test_final = copy.deepcopy(X_test_final.iloc[:, :num_of_columns])\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.astype(int)\n",
    "        self.X_test_final = X_test_final.reindex(X_train.columns, axis=1)\n",
    "        self.y_test_final = y_test_final.astype(int)\n",
    "        if self.algo == \"1_svm\":\n",
    "            classifier = OneClassSVM(gamma='auto')\n",
    "        elif self.algo == \"iso_f\":\n",
    "            classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        elif self.algo == \"out_fa\":\n",
    "            classifier = LocalOutlierFactor(novelty=True)\n",
    "        elif self.algo == \"ee\":\n",
    "            classifier = EllipticEnvelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            classifier = Birch()\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "        scores = []\n",
    "        best_model = None\n",
    "        best_avg_score = 0.0 \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index].astype(int), y_train.iloc[val_index].astype(int)\n",
    "\n",
    "            # Train the model on the training fold\n",
    "            X_train_smote, y_train_smote = X_train_fold, y_train_fold\n",
    "            classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            # Evaluate the model on the validation fold\n",
    "            y_val_pred = classifier.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Update the best model if the current model has a better average performance\n",
    "            if score > best_avg_score:\n",
    "                best_avg_score = score\n",
    "                best_model = classifier\n",
    "            scores.append(score)\n",
    "        \n",
    "        self.classifier = best_model\n",
    "        return(best_avg_score, scores)\n",
    "    \n",
    "    def perform_filter_methods(self):\n",
    "        data = copy.deepcopy(self.dataset)\n",
    "        X = copy.deepcopy(data).drop(columns=['Bankrupt?'])  # Features\n",
    "        print(\"total features = \", len(X.columns))\n",
    "        y = copy.deepcopy(data['Bankrupt?']).astype(int) \n",
    "        # Calculate Mutual Information scores\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        # Select features with MI score > 0.5\n",
    "        selected_features = X.columns[mi_scores > 0.01]\n",
    "        print(\"selected features with high mutual information with the target = \", len(selected_features))\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = X[selected_features].corr().abs()\n",
    "        copy_ds = copy.deepcopy(data[selected_features])\n",
    "        # Remove one of two highly correlated features\n",
    "        to_drop = set()\n",
    "        dropped_columns = {}\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            if i not in dropped_columns:\n",
    "                for j in range(len(corr_matrix.columns)):\n",
    "                    if abs(corr_matrix.iloc[i, j]) > 0.8 and i!=j and j not in dropped_columns and i not in dropped_columns and i!=j:\n",
    "                        \n",
    "                        colname_i = corr_matrix.columns[i]\n",
    "                        colname_j = corr_matrix.columns[j]\n",
    "                        # Calculate the Mutual Information score of each feature with the target variable\n",
    "                        mi_i = mutual_info_classif(X[colname_i].values.reshape(-1, 1), y)[0]\n",
    "                        mi_j = mutual_info_classif(X[colname_j].values.reshape(-1, 1), y)[0]\n",
    "                        # Keep the feature with higher Mutual Information score\n",
    "                        if mi_i > mi_j:\n",
    "                            to_drop.add(colname_j)\n",
    "                            dropped_columns[j] = colname_j\n",
    "                        else:\n",
    "                            to_drop.add(colname_i)\n",
    "                            dropped_columns[i] = colname_i\n",
    "        final_selected_features = selected_features.drop(to_drop)\n",
    "        print(\"final selected features after removing one of two correlated features = \", len(final_selected_features))\n",
    "        self.dataset = self.dataset[final_selected_features]\n",
    "        self.dataset[\"Bankrupt?\"] = data[\"Bankrupt?\"]\n",
    "        self.show_heat_map()\n",
    "        return self.dataset\n",
    "    \n",
    "    def perform_wrapper_method(self):\n",
    "        feature_scores = []\n",
    "        feature_scores_dict = {}\n",
    "        total_num_of_columns = len(self.X.columns)\n",
    "        for i in range(1,total_num_of_columns+1):\n",
    "            newAnlyzr = DataAnalyzer(balance_weights=self.balance_weights)\n",
    "            newAnlyzr.get_x_and_Y()\n",
    "            (best_avg_score, scores) = newAnlyzr.perform_kfold_cv(num_of_columns=i)\n",
    "            mean_score, y_tst, y_prd = newAnlyzr.get_accuracy()\n",
    "            feature_scores.append((i, mean_score))\n",
    "            feature_scores_dict[i] = mean_score\n",
    "        self.feature_scores = feature_scores\n",
    "        additional_feature_penalty = -0.05\n",
    "        score_weight = 0.95\n",
    "        adjusted_scores = []\n",
    "        best_num_of_features = 1\n",
    "        best_adjusted_score = 0\n",
    "        for (j, mn_score) in feature_scores:\n",
    "            adjusted_score = mn_score*score_weight + j*additional_feature_penalty/total_num_of_columns\n",
    "            adjusted_scores.append((j, adjusted_score))\n",
    "            if adjusted_score > best_adjusted_score:\n",
    "                best_adjusted_score = adjusted_score\n",
    "                best_num_of_features = j\n",
    "        best_score = feature_scores_dict[best_num_of_features]\n",
    "\n",
    "        return {\n",
    "            \"best_num_of_features\": best_num_of_features,\n",
    "            \"best_score\": best_score\n",
    "        }\n",
    "    \n",
    "    def plot_wrapper_scores(self):\n",
    "        x_values, y_values = zip(*self.feature_scores)\n",
    "        # Create a Plotly trace\n",
    "        trace = go.Scatter(x=x_values, y=y_values, mode='lines+markers')\n",
    "\n",
    "        # Create a Plotly layout\n",
    "        layout = go.Layout(\n",
    "            title='Wrapper Method Feature Scores',\n",
    "            xaxis=dict(title='Number of Features'),\n",
    "            yaxis=dict(title='Accuracy')\n",
    "        )\n",
    "\n",
    "        # Create a Plotly figure\n",
    "        fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "\n",
    "    def perform_pca(self, n_components=None):\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        data = self.X\n",
    "        standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "        # Create PCA object\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        # Fit and transform the data\n",
    "        pca_data = pca.fit_transform(standardized_data)\n",
    "\n",
    "        # Create a DataFrame for the PCA results\n",
    "        pca_columns = [f\"PC{i+1}\" for i in range(pca_data.shape[1])]\n",
    "        pca_df = pd.DataFrame(data=pca_data, columns=pca_columns)\n",
    "\n",
    "        # Concatenate with original dataset\n",
    "        self.X = pca_df\n",
    "\n",
    "    \n",
    "    def perform_without_cv(self):\n",
    "        if self.algo == \"1_svm\":\n",
    "            classifier = OneClassSVM(gamma='auto')\n",
    "        elif self.algo == \"iso_f\":\n",
    "            classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        elif self.algo == \"out_fa\":\n",
    "            classifier = LocalOutlierFactor(novelty=True)\n",
    "        elif self.algo == \"ee\":\n",
    "            classifier = EllipticEnvelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            classifier = Birch()\n",
    "        self.classifier = classifier\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_test_final)\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred1)\n",
    "        return self.ac_final, self.y_test_final\n",
    "    \n",
    "    def one_svm(self):\n",
    "        self.classifier = OneClassSVM(gamma='auto')\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_cv)\n",
    "        y_pred1 = [0 if pred == 1 else 1 for pred in y_pred1]\n",
    "        self.ac_cv = accuracy_score(self.y_cv,y_pred1)\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def isolation_forest(self):\n",
    "        self.classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def outlier_factor(self):\n",
    "        self.classifier = LocalOutlierFactor(novelty=True)\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def elliptic_envelope(self):\n",
    "        self.classifier = EllipticEnvelope()\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def one_birch(self):\n",
    "        self.classifier = Birch()\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        smallest_cluster_id = min(y_pred)\n",
    "        # Treat data points in the smallest cluster as anomalies (label them as 1)\n",
    "        y_pred = [1 if pred == smallest_cluster_id else 0 for pred in y_pred]\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        y_pred_final = self.classifier.predict(self.X_test_final)\n",
    "        if self.algo == '1_b':\n",
    "            smallest_cluster_id = min(y_pred_final)\n",
    "            # Treat data points in the smallest cluster as anomalies (label them as 1)\n",
    "            y_pred_final = [1 if pred == smallest_cluster_id else 0 for pred in y_pred_final]\n",
    "        else:\n",
    "            y_pred_final = [0 if pred == 1 else 1 for pred in y_pred_final]\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred_final)\n",
    "        return self.ac_final, self.y_test_final, y_pred_final\n",
    "\n",
    "class Master:\n",
    "    def __init__(self, balance_weights = True, algo = \"knn\"):\n",
    "        self.results = {}\n",
    "        self.balance_weights = balance_weights\n",
    "        self.algo = algo\n",
    "\n",
    "    def print_classification_report(self, y_true, y_pred):\n",
    "        report = classification_report(y_true, y_pred, target_names=['Negative Class', 'Positive Class'], output_dict=True)\n",
    "        print(\"{:<20} {:<15} {:<15} {:<15} {:<15}\".format('', 'precision', 'recall', 'f1-score', 'support'))\n",
    "        for class_name, metrics in report.items():\n",
    "            if class_name in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                continue\n",
    "            print(\"{:<20} {:<15.2f} {:<15.2f} {:<15.2f} {:<15}\".format(class_name,\n",
    "                                                                       metrics['precision'],\n",
    "                                                                       metrics['recall'],\n",
    "                                                                       metrics['f1-score'],\n",
    "                                                                       metrics['support']))\n",
    "        \n",
    "    def organize_results(self):\n",
    "        items = []\n",
    "        for k, v in self.results.items():\n",
    "            print(k, v)\n",
    "            if isinstance(v, dict):\n",
    "                for xk, xv in v.items():\n",
    "                    new_x_key = xk\n",
    "                    items.append((new_x_key, xv))\n",
    "            else:\n",
    "                new_key = k\n",
    "                items.append((new_key, v))\n",
    "        r_items = dict(items)\n",
    "        df = pd.DataFrame({'method': list(r_items.keys()), 'result': list(r_items.values())})\n",
    "        return df\n",
    "\n",
    "    def run_without_cv(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_without_cv()\n",
    "        rslts, y_pred = anlyzr.perform_without_cv()\n",
    "        self.results[\"run without cv\"] = rslts\n",
    "        self.print_classification_report(anlyzr.y_test_final, y_pred)\n",
    "\n",
    "    def run_with_cv(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        \n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"run with cv\"], y_test_final, y_pred_final = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_kfold(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        (best_avg_score, scores) = anlyzr.perform_kfold_cv()\n",
    "        rslt, y_test_final, y_pred_final =  anlyzr.get_accuracy()\n",
    "        self.results[\"after_k_fold_run\"] = {\n",
    "            \"best kfold cv score\": best_avg_score,\n",
    "            \"scores\": scores,\n",
    "            \"final kfold score on test dataset\": rslt\n",
    "        }\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_filter(self):\n",
    "        # Implement feature selection using filter method (e.g., correlation)\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.perform_filter_methods()\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"with_filter_method\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_wrapper(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        self.results = anlyzr.perform_wrapper_method()\n",
    "        anlyzr.plot_wrapper_scores()\n",
    "\n",
    "    def run_with_pca(self):\n",
    "        # Implement feature selection using PCA\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_pca(n_components=2)\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"with_pca\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "    \n",
    "    def run_cv_problem(self):\n",
    "        self.run_without_cv()\n",
    "        self.run_with_cv()\n",
    "        self.run_with_kfold()\n",
    "        return self.results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.99            0.50            0.67            1315.0         \n",
      "Positive Class       0.06            0.86            0.11            49.0           \n",
      "with_pca 0.5146627565982405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.514663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.514663"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"1_svm\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.98            0.89            0.93            1315.0         \n",
      "Positive Class       0.13            0.45            0.20            49.0           \n",
      "with_pca 0.8709677419354839\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.870968"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"iso_f\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.97            0.99            0.98            1315.0         \n",
      "Positive Class       0.23            0.10            0.14            49.0           \n",
      "with_pca 0.9552785923753666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.955279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.955279"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"out_fa\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.98            0.91            0.94            1315.0         \n",
      "Positive Class       0.15            0.43            0.22            49.0           \n",
      "with_pca 0.8900293255131965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.890029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.890029"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"ee\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.84            0.17            0.28            1315.0         \n",
      "Positive Class       0.01            0.12            0.01            49.0           \n",
      "with_pca 0.16495601173020527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.164956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.164956"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"1_b\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assgn_3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

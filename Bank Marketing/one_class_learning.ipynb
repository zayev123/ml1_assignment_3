{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/4226470787.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import copy\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import Birch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor = KNN\n",
    "# Isolation forest = random forest\n",
    "# One-Class SVM = SVM\n",
    "# Elliptic Envelope = Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyzer:\n",
    "    def __init__(self, algo = \"knn\"):\n",
    "        file_path = 'bank-full.csv'\n",
    "\n",
    "        self.dataset = pd.read_csv(file_path, header=None, sep=';')\n",
    "        self.dataset.columns = self.dataset.iloc[0]\n",
    "\n",
    "        self.dataset = self.dataset.drop(0)\n",
    "        self.original_dataset = self.dataset\n",
    "        self.algo = algo\n",
    "        self.encode_categorical()\n",
    "\n",
    "    \n",
    "    def encode_categorical(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        for column in self.dataset.columns:\n",
    "            if column in [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\", \"y\"]:  # Check if column is 'diagnosis'\n",
    "                encoded_values = label_encoder.fit_transform(self.dataset[column])\n",
    "                self.dataset.loc[:, column] = encoded_values\n",
    "            elif column in [\"balance\", \"age\", \"duration\"]:  # Convert all other columns to 'double'\n",
    "                self.dataset.loc[:, column] = self.dataset[column].astype(float)\n",
    "            else:\n",
    "                self.dataset.loc[:, column] = self.dataset[column].astype(int)\n",
    "        \n",
    "        self.dataset[\"y\"] = self.dataset[\"y\"].astype(int)\n",
    "    \n",
    "    def convert_columns(self):\n",
    "        # Convert all columns to float except 'y' and 'Net Income Flag'\n",
    "        for column in self.dataset.columns:\n",
    "            if column not in ['y', 'Net Income Flag']:\n",
    "                self.dataset[column] = self.dataset[column].astype(float)\n",
    "            else:\n",
    "                self.dataset[column] = self.dataset[column].astype(int)\n",
    "\n",
    "    def show_class_distribution(self):\n",
    "        target_column = 'y'\n",
    "        # Load your dataset into a pandas DataFrame\n",
    "\n",
    "        # Step 2: Inspect the Target Variable\n",
    "        class_distribution = self.dataset[target_column].value_counts()\n",
    "\n",
    "        # Step 3: Visualize the Distribution\n",
    "        class_distribution.plot(kind='bar', title='Target Variable Distribution')\n",
    "        print(class_distribution)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "    def show_heat_map(self, dataset = None):\n",
    "        if dataset is None:\n",
    "            corr_matrix = self.dataset.corr()\n",
    "        else:\n",
    "            corr_matrix = dataset.corr()\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_x_and_Y(self):\n",
    "        self.X = self.dataset.drop('y', axis=1)  # Assuming 'p' is the target variable\n",
    "        self.y = self.dataset['y']\n",
    "        return (self.X, self.y)\n",
    "    \n",
    "    def perform_manual_splitting_without_cv(self):\n",
    "        X_train, self.X_test_final, y_train, self.y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "    \n",
    "    def perform_manual_splitting_cv(self):\n",
    "        # First split to get training set and first test set\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(self.X, self.y, test_size=0.4, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_cv, self.X_test_final, self.y_cv, self.y_test_final = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "    \n",
    "    def perform_kfold_cv(self, num_of_columns = None):\n",
    "        X_train, X_test_final, y_train, y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        if num_of_columns:\n",
    "            X_train = copy.deepcopy(X_train.iloc[:, :num_of_columns])\n",
    "            X_test_final = copy.deepcopy(X_test_final.iloc[:, :num_of_columns])\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.astype(int)\n",
    "        self.X_test_final = X_test_final.reindex(X_train.columns, axis=1)\n",
    "        self.y_test_final = y_test_final.astype(int)\n",
    "        if self.algo == \"1_svm\":\n",
    "            classifier = OneClassSVM(gamma='auto')\n",
    "        elif self.algo == \"iso_f\":\n",
    "            classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        elif self.algo == \"out_fa\":\n",
    "            classifier = LocalOutlierFactor(novelty=True)\n",
    "        elif self.algo == \"ee\":\n",
    "            classifier = EllipticEnvelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            classifier = Birch()\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "        scores = []\n",
    "        best_model = None\n",
    "        best_avg_score = 0.0 \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index].astype(int), y_train.iloc[val_index].astype(int)\n",
    "\n",
    "            # Train the model on the training fold\n",
    "            X_train_smote, y_train_smote = X_train_fold, y_train_fold\n",
    "            classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            # Evaluate the model on the validation fold\n",
    "            y_val_pred = classifier.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Update the best model if the current model has a better average performance\n",
    "            if score > best_avg_score:\n",
    "                best_avg_score = score\n",
    "                best_model = classifier\n",
    "            scores.append(score)\n",
    "        \n",
    "        self.classifier = best_model\n",
    "        return(best_avg_score, scores)\n",
    "    \n",
    "    def perform_filter_methods(self):\n",
    "        data = copy.deepcopy(self.dataset)\n",
    "        X = copy.deepcopy(data).drop(columns=['y'])  # Features\n",
    "        print(\"total features = \", len(X.columns))\n",
    "        y = copy.deepcopy(data['y']).astype(int) \n",
    "        # Calculate Mutual Information scores\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        # Select features with MI score > 0.5\n",
    "        selected_features = X.columns[mi_scores > 0.01]\n",
    "        print(\"selected features with high mutual information with the target = \", len(selected_features))\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = X[selected_features].corr().abs()\n",
    "        copy_ds = copy.deepcopy(data[selected_features])\n",
    "        # Remove one of two highly correlated features\n",
    "        to_drop = set()\n",
    "        dropped_columns = {}\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            if i not in dropped_columns:\n",
    "                for j in range(len(corr_matrix.columns)):\n",
    "                    if abs(corr_matrix.iloc[i, j]) > 0.8 and i!=j and j not in dropped_columns and i not in dropped_columns and i!=j:\n",
    "                        \n",
    "                        colname_i = corr_matrix.columns[i]\n",
    "                        colname_j = corr_matrix.columns[j]\n",
    "                        # Calculate the Mutual Information score of each feature with the target variable\n",
    "                        mi_i = mutual_info_classif(X[colname_i].values.reshape(-1, 1), y)[0]\n",
    "                        mi_j = mutual_info_classif(X[colname_j].values.reshape(-1, 1), y)[0]\n",
    "                        # Keep the feature with higher Mutual Information score\n",
    "                        if mi_i > mi_j:\n",
    "                            to_drop.add(colname_j)\n",
    "                            dropped_columns[j] = colname_j\n",
    "                        else:\n",
    "                            to_drop.add(colname_i)\n",
    "                            dropped_columns[i] = colname_i\n",
    "        final_selected_features = selected_features.drop(to_drop)\n",
    "        print(\"final selected features after removing one of two correlated features = \", len(final_selected_features))\n",
    "        self.dataset = self.dataset[final_selected_features]\n",
    "        self.dataset[\"y\"] = data[\"y\"]\n",
    "        self.show_heat_map()\n",
    "        return self.dataset\n",
    "    \n",
    "    def perform_wrapper_method(self):\n",
    "        feature_scores = []\n",
    "        feature_scores_dict = {}\n",
    "        total_num_of_columns = len(self.X.columns)\n",
    "        for i in range(1,total_num_of_columns+1):\n",
    "            newAnlyzr = DataAnalyzer()\n",
    "            newAnlyzr.get_x_and_Y()\n",
    "            (best_avg_score, scores) = newAnlyzr.perform_kfold_cv(num_of_columns=i)\n",
    "            mean_score, y_tst, y_prd = newAnlyzr.get_accuracy()\n",
    "            feature_scores.append((i, mean_score))\n",
    "            feature_scores_dict[i] = mean_score\n",
    "        self.feature_scores = feature_scores\n",
    "        additional_feature_penalty = -0.05\n",
    "        score_weight = 0.95\n",
    "        adjusted_scores = []\n",
    "        best_num_of_features = 1\n",
    "        best_adjusted_score = 0\n",
    "        for (j, mn_score) in feature_scores:\n",
    "            adjusted_score = mn_score*score_weight + j*additional_feature_penalty/total_num_of_columns\n",
    "            adjusted_scores.append((j, adjusted_score))\n",
    "            if adjusted_score > best_adjusted_score:\n",
    "                best_adjusted_score = adjusted_score\n",
    "                best_num_of_features = j\n",
    "        best_score = feature_scores_dict[best_num_of_features]\n",
    "\n",
    "        return {\n",
    "            \"best_num_of_features\": best_num_of_features,\n",
    "            \"best_score\": best_score\n",
    "        }\n",
    "    \n",
    "    def plot_wrapper_scores(self):\n",
    "        x_values, y_values = zip(*self.feature_scores)\n",
    "        # Create a Plotly trace\n",
    "        trace = go.Scatter(x=x_values, y=y_values, mode='lines+markers')\n",
    "\n",
    "        # Create a Plotly layout\n",
    "        layout = go.Layout(\n",
    "            title='Wrapper Method Feature Scores',\n",
    "            xaxis=dict(title='Number of Features'),\n",
    "            yaxis=dict(title='Accuracy')\n",
    "        )\n",
    "\n",
    "        # Create a Plotly figure\n",
    "        fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "\n",
    "    def perform_pca(self, n_components=None):\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        data = self.X\n",
    "        standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "        # Create PCA object\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        # Fit and transform the data\n",
    "        pca_data = pca.fit_transform(standardized_data)\n",
    "\n",
    "        # Create a DataFrame for the PCA results\n",
    "        pca_columns = [f\"PC{i+1}\" for i in range(pca_data.shape[1])]\n",
    "        pca_df = pd.DataFrame(data=pca_data, columns=pca_columns)\n",
    "\n",
    "        # Concatenate with original dataset\n",
    "        self.X = pca_df\n",
    "\n",
    "    \n",
    "    def perform_without_cv(self):\n",
    "        if self.algo == \"1_svm\":\n",
    "            classifier = OneClassSVM(gamma='auto')\n",
    "        elif self.algo == \"iso_f\":\n",
    "            classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        elif self.algo == \"out_fa\":\n",
    "            classifier = LocalOutlierFactor(novelty=True)\n",
    "        elif self.algo == \"ee\":\n",
    "            classifier = EllipticEnvelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            classifier = Birch()\n",
    "        self.classifier = classifier\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_test_final)\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred1)\n",
    "        return self.ac_final, self.y_test_final\n",
    "    \n",
    "    def one_svm(self):\n",
    "        self.classifier = OneClassSVM(gamma='auto')\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_cv)\n",
    "        y_pred1 = [0 if pred == 1 else 1 for pred in y_pred1]\n",
    "        self.ac_cv = accuracy_score(self.y_cv,y_pred1)\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def isolation_forest(self):\n",
    "        self.classifier = IsolationForest(random_state=42, contamination='auto')\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def outlier_factor(self):\n",
    "        self.classifier = LocalOutlierFactor(novelty=True)\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def elliptic_envelope(self):\n",
    "        self.classifier = EllipticEnvelope()\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def one_birch(self):\n",
    "        self.classifier = Birch()\n",
    "        self.classifier.fit(self.X_train)\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        smallest_cluster_id = min(y_pred)\n",
    "        # Treat data points in the smallest cluster as anomalies (label them as 1)\n",
    "        y_pred = [1 if pred == smallest_cluster_id else 0 for pred in y_pred]\n",
    "        # distinct_values = np.unique(y_pred)\n",
    "        # print(distinct_values)\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        y_pred_final = self.classifier.predict(self.X_test_final)\n",
    "        if self.algo == '1_b':\n",
    "            smallest_cluster_id = min(y_pred_final)\n",
    "            # Treat data points in the smallest cluster as anomalies (label them as 1)\n",
    "            y_pred_final = [1 if pred == smallest_cluster_id else 0 for pred in y_pred_final]\n",
    "        else:\n",
    "            y_pred_final = [0 if pred == 1 else 1 for pred in y_pred_final]\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred_final)\n",
    "        return self.ac_final, self.y_test_final, y_pred_final\n",
    "\n",
    "class Master:\n",
    "    def __init__(self, algo = \"knn\"):\n",
    "        self.results = {}\n",
    "        self.algo = algo\n",
    "\n",
    "    def print_classification_report(self, y_true, y_pred):\n",
    "        report = classification_report(y_true, y_pred, target_names=['Negative Class', 'Positive Class'], output_dict=True)\n",
    "        print(\"{:<20} {:<15} {:<15} {:<15} {:<15}\".format('', 'precision', 'recall', 'f1-score', 'support'))\n",
    "        for class_name, metrics in report.items():\n",
    "            if class_name in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                continue\n",
    "            print(\"{:<20} {:<15.2f} {:<15.2f} {:<15.2f} {:<15}\".format(class_name,\n",
    "                                                                       metrics['precision'],\n",
    "                                                                       metrics['recall'],\n",
    "                                                                       metrics['f1-score'],\n",
    "                                                                       metrics['support']))\n",
    "        \n",
    "    def organize_results(self):\n",
    "        items = []\n",
    "        for k, v in self.results.items():\n",
    "            print(k, v)\n",
    "            if isinstance(v, dict):\n",
    "                for xk, xv in v.items():\n",
    "                    new_x_key = xk\n",
    "                    items.append((new_x_key, xv))\n",
    "            else:\n",
    "                new_key = k\n",
    "                items.append((new_key, v))\n",
    "        r_items = dict(items)\n",
    "        df = pd.DataFrame({'method': list(r_items.keys()), 'result': list(r_items.values())})\n",
    "        return df\n",
    "\n",
    "    def run_without_cv(self):\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_without_cv()\n",
    "        rslts, y_pred = anlyzr.perform_without_cv()\n",
    "        self.results[\"run without cv\"] = rslts\n",
    "        self.print_classification_report(anlyzr.y_test_final, y_pred)\n",
    "\n",
    "    def run_with_cv(self):\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        \n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"run with cv\"], y_test_final, y_pred_final = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_kfold(self):\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        (best_avg_score, scores) = anlyzr.perform_kfold_cv()\n",
    "        rslt, y_test_final, y_pred_final =  anlyzr.get_accuracy()\n",
    "        self.results[\"after_k_fold_run\"] = {\n",
    "            \"best kfold cv score\": best_avg_score,\n",
    "            \"scores\": scores,\n",
    "            \"final kfold score on test dataset\": rslt\n",
    "        }\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_filter(self):\n",
    "        # Implement feature selection using filter method (e.g., correlation)\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.perform_filter_methods()\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"with_filter_method\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_wrapper(self):\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        self.results = anlyzr.perform_wrapper_method()\n",
    "        anlyzr.plot_wrapper_scores()\n",
    "\n",
    "    def run_with_pca(self):\n",
    "        # Implement feature selection using PCA\n",
    "        anlyzr = DataAnalyzer(algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_pca(n_components=2)\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"1_svm\":\n",
    "            anlyzr.one_svm()\n",
    "        elif self.algo == \"iso_f\":\n",
    "            anlyzr.isolation_forest()\n",
    "        elif self.algo == \"out_fa\":\n",
    "            anlyzr.outlier_factor()\n",
    "        elif self.algo == \"ee\":\n",
    "            anlyzr.elliptic_envelope()\n",
    "        elif self.algo == \"1_b\":\n",
    "            anlyzr.one_birch()\n",
    "        self.results[\"with_pca\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "    \n",
    "    def run_cv_problem(self):\n",
    "        self.run_without_cv()\n",
    "        self.run_with_cv()\n",
    "        self.run_with_kfold()\n",
    "        return self.results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/2033850669.py:5: DtypeWarning: Columns (0,5,9,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataset = pd.read_csv(file_path, header=None, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       1.00            0.00            0.00            7999.0         \n",
      "Positive Class       0.12            1.00            0.21            1044.0         \n",
      "run with cv 0.11555899590843746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.115559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method    result\n",
       "0  run with cv  0.115559"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(algo=\"1_svm\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/2033850669.py:5: DtypeWarning: Columns (0,5,9,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataset = pd.read_csv(file_path, header=None, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.91            0.83            0.87            7999.0         \n",
      "Positive Class       0.22            0.36            0.28            1044.0         \n",
      "run with cv 0.7798297025323455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.77983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method   result\n",
       "0  run with cv  0.77983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(algo=\"iso_f\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/2033850669.py:5: DtypeWarning: Columns (0,5,9,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataset = pd.read_csv(file_path, header=None, sep=';')\n",
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.89            0.98            0.93            7999.0         \n",
      "Positive Class       0.31            0.05            0.09            1044.0         \n",
      "run with cv 0.8771425411920822\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.877143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method    result\n",
       "0  run with cv  0.877143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(algo=\"out_fa\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/2033850669.py:5: DtypeWarning: Columns (0,5,9,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataset = pd.read_csv(file_path, header=None, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.90            0.91            0.90            7999.0         \n",
      "Positive Class       0.22            0.19            0.20            1044.0         \n",
      "run with cv 0.8283755390910096\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.828376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method    result\n",
       "0  run with cv  0.828376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(algo=\"ee\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_56975/2033850669.py:5: DtypeWarning: Columns (0,5,9,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataset = pd.read_csv(file_path, header=None, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.89            0.91            0.90            7999.0         \n",
      "Positive Class       0.14            0.11            0.12            1044.0         \n",
      "run with cv 0.8183125069114232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.818313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method    result\n",
       "0  run with cv  0.818313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(algo=\"1_b\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assgn_3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

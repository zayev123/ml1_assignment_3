{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/fjh_5m0n2zj9r5lpl1nrd20m0000gn/T/ipykernel_60676/2829960177.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-05-18 15:27:27.203819: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import copy\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import statistics\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.layers import Dense\n",
    "from keras._tf_keras.keras.optimizers import Adam\n",
    "from keras._tf_keras.keras.losses import BinaryCrossentropy\n",
    "from keras._tf_keras.keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras._tf_keras.keras.optimizers import SGD, Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMLPClassifier:\n",
    "    def __init__(self, hidden_layer_size = 100, max_iter=100, random_state=None, class_weight =None, input_dim = 23):\n",
    "        if random_state:\n",
    "            tf.random.set_seed(random_state)\n",
    "            np.random.seed(random_state)\n",
    "            random.seed(random_state)\n",
    "        self.model = Sequential([\n",
    "            Dense(hidden_layer_size, activation='relu', input_dim=input_dim),\n",
    "            Dense(95, activation='relu'),\n",
    "            Dense(95, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        max_iter = 40\n",
    "        self.class_weight = class_weight\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def compile_model(self):\n",
    "        optimizer=Adam(learning_rate=0.0002)\n",
    "        loss='binary_crossentropy'\n",
    "        if self.class_weight:\n",
    "            binary_crossentropy_loss = BinaryCrossentropy()\n",
    "            custom_loss_lambda = lambda y_true, y_pred: tf.where(tf.logical_and(y_true == 1, y_true != y_pred), 2800 * binary_crossentropy_loss(y_true, y_pred), 1*binary_crossentropy_loss(y_true, y_pred))\n",
    "            self.model.compile(optimizer=optimizer, loss=custom_loss_lambda, metrics=['accuracy'], )\n",
    "        else:\n",
    "            self.model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    def fit(self, X_train, y_train, **kwargs):\n",
    "        X_train = X_train.values\n",
    "        y_train = y_train.values\n",
    "        self.model.fit(X_train, y_train, epochs=self.max_iter, batch_size=32, verbose=1, initial_epoch=1, validation_split=0.1, shuffle=False, **kwargs)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        dta = self.model.predict(X_test)\n",
    "        arr_list = dta.flatten().tolist()\n",
    "        grtr = 0\n",
    "        lssr = 0\n",
    "        arr_list_int = []\n",
    "        for k in arr_list:\n",
    "            if k > 0.5:\n",
    "                arr_list_int.append(1)\n",
    "                grtr = grtr + 1\n",
    "            else:\n",
    "                arr_list_int.append(0)\n",
    "                lssr = lssr + 1\n",
    "\n",
    "        return arr_list_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyzer:\n",
    "    def __init__(self, balance_weights = True, algo = \"knn\"):\n",
    "        file_path = 'default of credit card clients.csv'\n",
    "\n",
    "        self.dataset = pd.read_csv(file_path, header=None)\n",
    "        self.dataset.columns = self.dataset.iloc[1]\n",
    "\n",
    "        self.dataset = self.dataset.drop([0, 1])\n",
    "        self.dataset = self.dataset.drop(self.dataset.columns[0], axis=1)\n",
    "        # Reset the index\n",
    "        self.dataset = self.dataset.reset_index(drop=True)\n",
    "        self.original_dataset = self.dataset\n",
    "        self.convert_columns()\n",
    "        self.balance_weights = balance_weights\n",
    "        self.algo = algo\n",
    "        self.knn_weight = \"uniform\"\n",
    "        self.class_weight = None\n",
    "        if balance_weights:\n",
    "            self.knn_weight = \"distance\"\n",
    "            self.class_weight = \"balanced\"\n",
    "        print(self.class_weight)\n",
    "\n",
    "    \n",
    "    def convert_columns(self):\n",
    "        # Convert all columns to float except 'default payment next month' and 'Net Income Flag'\n",
    "        for column in self.dataset.columns:\n",
    "            if column not in [\"ID\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\", \"default payment next month\"]:\n",
    "                self.dataset[column] = self.dataset[column].astype(float)\n",
    "            else:\n",
    "                self.dataset[column] = self.dataset[column].astype(int)\n",
    "\n",
    "    def show_class_distribution(self):\n",
    "        target_column = 'default payment next month'\n",
    "        # Load your dataset into a pandas DataFrame\n",
    "\n",
    "        # Step 2: Inspect the Target Variable\n",
    "        class_distribution = self.dataset[target_column].value_counts()\n",
    "\n",
    "        # Step 3: Visualize the Distribution\n",
    "        class_distribution.plot(kind='bar', title='Target Variable Distribution')\n",
    "        print(class_distribution)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "    def show_heat_map(self, dataset = None):\n",
    "        if dataset is None:\n",
    "            corr_matrix = self.dataset.corr()\n",
    "        else:\n",
    "            corr_matrix = dataset.corr()\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_x_and_Y(self):\n",
    "        self.X = self.dataset.drop('default payment next month', axis=1)  # Assuming 'p' is the target variable\n",
    "        self.y = self.dataset['default payment next month']\n",
    "        return (self.X, self.y)\n",
    "    \n",
    "    def perform_manual_splitting_without_cv(self):\n",
    "        X_train, self.X_test_final, y_train, self.y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "    \n",
    "    def perform_manual_splitting_cv(self):\n",
    "        # First split to get training set and first test set\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(self.X, self.y, test_size=0.4, random_state=0)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_cv, self.X_test_final, self.y_cv, self.y_test_final = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "    \n",
    "    def perform_kfold_cv(self, num_of_columns = None):\n",
    "        X_train, X_test_final, y_train, y_test_final = train_test_split(self.X, self.y, test_size=0.2, random_state=0)\n",
    "        if num_of_columns:\n",
    "            X_train = copy.deepcopy(X_train.iloc[:, :num_of_columns])\n",
    "            X_test_final = copy.deepcopy(X_test_final.iloc[:, :num_of_columns])\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.astype(int)\n",
    "        self.X_test_final = X_test_final.reindex(X_train.columns, axis=1)\n",
    "        self.y_test_final = y_test_final.astype(int)\n",
    "        if self.algo == \"knn\":\n",
    "            classifier = KNeighborsClassifier(n_neighbors = 40, metric = 'minkowski', p = 2.7, weights=self.knn_weight)\n",
    "        elif self.algo == \"rf\":\n",
    "            classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"svm\":\n",
    "            classifier = SVC(kernel='rbf', random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"logreg\":\n",
    "            classifier = LogisticRegression(random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"nn\":\n",
    "            # classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, random_state=42) \n",
    "            custom_mlp = CustomMLPClassifier(max_iter=100, random_state=42, class_weight=self.class_weight)\n",
    "            custom_mlp.compile_model()  # You may need to pass additional parameters here depending on your requirements\n",
    "            classifier = custom_mlp\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "        scores = []\n",
    "        best_model = None\n",
    "        best_avg_score = 0.0 \n",
    "\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index].astype(int), y_train.iloc[val_index].astype(int)\n",
    "\n",
    "            # Train the model on the training fold\n",
    "            X_train_smote, y_train_smote = X_train_fold, y_train_fold\n",
    "            classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            # Evaluate the model on the validation fold\n",
    "            y_val_pred = classifier.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Update the best model if the current model has a better average performance\n",
    "            if score > best_avg_score:\n",
    "                best_avg_score = score\n",
    "                best_model = classifier\n",
    "            scores.append(score)\n",
    "        \n",
    "        self.classifier = best_model\n",
    "        return(best_avg_score, scores)\n",
    "    \n",
    "    def perform_filter_methods(self):\n",
    "        data = copy.deepcopy(self.dataset)\n",
    "        X = copy.deepcopy(data).drop(columns=['default payment next month'])  # Features\n",
    "        print(\"total features = \", len(X.columns))\n",
    "        y = copy.deepcopy(data['default payment next month']).astype(int) \n",
    "        # Calculate Mutual Information scores\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        # Select features with MI score > 0.5\n",
    "        selected_features = X.columns[mi_scores > 0.01]\n",
    "        print(\"selected features with high mutual information with the target = \", len(selected_features))\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = X[selected_features].corr().abs()\n",
    "        copy_ds = copy.deepcopy(data[selected_features])\n",
    "        # Remove one of two highly correlated features\n",
    "        to_drop = set()\n",
    "        dropped_columns = {}\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            if i not in dropped_columns:\n",
    "                for j in range(len(corr_matrix.columns)):\n",
    "                    if abs(corr_matrix.iloc[i, j]) > 0.8 and i!=j and j not in dropped_columns and i not in dropped_columns and i!=j:\n",
    "                        \n",
    "                        colname_i = corr_matrix.columns[i]\n",
    "                        colname_j = corr_matrix.columns[j]\n",
    "                        # Calculate the Mutual Information score of each feature with the target variable\n",
    "                        mi_i = mutual_info_classif(X[colname_i].values.reshape(-1, 1), y)[0]\n",
    "                        mi_j = mutual_info_classif(X[colname_j].values.reshape(-1, 1), y)[0]\n",
    "                        # Keep the feature with higher Mutual Information score\n",
    "                        if mi_i > mi_j:\n",
    "                            to_drop.add(colname_j)\n",
    "                            dropped_columns[j] = colname_j\n",
    "                        else:\n",
    "                            to_drop.add(colname_i)\n",
    "                            dropped_columns[i] = colname_i\n",
    "        final_selected_features = selected_features.drop(to_drop)\n",
    "        print(\"final selected features after removing one of two correlated features = \", len(final_selected_features))\n",
    "        self.dataset = self.dataset[final_selected_features]\n",
    "        self.dataset[\"default payment next month\"] = data[\"default payment next month\"]\n",
    "        self.show_heat_map()\n",
    "        return self.dataset\n",
    "    \n",
    "    def perform_wrapper_method(self):\n",
    "        feature_scores = []\n",
    "        feature_scores_dict = {}\n",
    "        total_num_of_columns = len(self.X.columns)\n",
    "        for i in range(1,total_num_of_columns+1):\n",
    "            newAnlyzr = DataAnalyzer(balance_weights=self.balance_weights)\n",
    "            newAnlyzr.get_x_and_Y()\n",
    "            (best_avg_score, scores) = newAnlyzr.perform_kfold_cv(num_of_columns=i)\n",
    "            mean_score, y_tst, y_prd = newAnlyzr.get_accuracy()\n",
    "            feature_scores.append((i, mean_score))\n",
    "            feature_scores_dict[i] = mean_score\n",
    "        self.feature_scores = feature_scores\n",
    "        additional_feature_penalty = -0.05\n",
    "        score_weight = 0.95\n",
    "        adjusted_scores = []\n",
    "        best_num_of_features = 1\n",
    "        best_adjusted_score = 0\n",
    "        for (j, mn_score) in feature_scores:\n",
    "            adjusted_score = mn_score*score_weight + j*additional_feature_penalty/total_num_of_columns\n",
    "            adjusted_scores.append((j, adjusted_score))\n",
    "            if adjusted_score > best_adjusted_score:\n",
    "                best_adjusted_score = adjusted_score\n",
    "                best_num_of_features = j\n",
    "        best_score = feature_scores_dict[best_num_of_features]\n",
    "\n",
    "        return {\n",
    "            \"best_num_of_features\": best_num_of_features,\n",
    "            \"best_score\": best_score\n",
    "        }\n",
    "    \n",
    "    def plot_wrapper_scores(self):\n",
    "        x_values, y_values = zip(*self.feature_scores)\n",
    "        # Create a Plotly trace\n",
    "        trace = go.Scatter(x=x_values, y=y_values, mode='lines+markers')\n",
    "\n",
    "        # Create a Plotly layout\n",
    "        layout = go.Layout(\n",
    "            title='Wrapper Method Feature Scores',\n",
    "            xaxis=dict(title='Number of Features'),\n",
    "            yaxis=dict(title='Accuracy')\n",
    "        )\n",
    "\n",
    "        # Create a Plotly figure\n",
    "        fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n",
    "\n",
    "    def perform_pca(self, n_components=None):\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        data = self.X\n",
    "        standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "        # Create PCA object\n",
    "        pca = PCA(n_components=n_components)\n",
    "\n",
    "        # Fit and transform the data\n",
    "        pca_data = pca.fit_transform(standardized_data)\n",
    "\n",
    "        # Create a DataFrame for the PCA results\n",
    "        pca_columns = [f\"PC{i+1}\" for i in range(pca_data.shape[1])]\n",
    "        pca_df = pd.DataFrame(data=pca_data, columns=pca_columns)\n",
    "\n",
    "        # Concatenate with original dataset\n",
    "        self.X = pca_df\n",
    "\n",
    "    \n",
    "    def perform_without_cv(self):\n",
    "        if self.algo == \"knn\":\n",
    "            classifier = KNeighborsClassifier(n_neighbors = 40, metric = 'minkowski', p = 2.7, weights=self.knn_weight)\n",
    "        elif self.algo == \"rf\":\n",
    "            classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"svm\":\n",
    "            classifier = SVC(kernel='rbf', random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"logreg\":\n",
    "            classifier = LogisticRegression(random_state=42, class_weight=self.class_weight)\n",
    "        elif self.algo == \"nn\":\n",
    "            # classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, random_state=42,) \n",
    "            custom_mlp = CustomMLPClassifier(max_iter=100, random_state=42, class_weight=self.class_weight)\n",
    "            custom_mlp.compile_model()  # You may need to pass additional parameters here depending on your requirements\n",
    "            classifier = custom_mlp\n",
    "        self.classifier = classifier\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_test_final)\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred1)\n",
    "        return self.ac_final, self.y_test_final\n",
    "    \n",
    "    def perform_knn(self):\n",
    "        self.classifier = KNeighborsClassifier(n_neighbors = 20, metric = 'minkowski', p = 2.7, weights=self.knn_weight)\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        y_pred1 = self.classifier.predict(self.X_cv)\n",
    "        self.ac_cv = accuracy_score(self.y_cv,y_pred1)\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def perform_random_forest(self):\n",
    "        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=self.class_weight)  # Initialize the Random Forest Classifier\n",
    "        self.classifier.fit(self.X_train, self.y_train)  # Train the classifier\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def perform_svm(self):\n",
    "        self.classifier = SVC(kernel='rbf', random_state=42, class_weight=self.class_weight)  # Initialize the SVM Classifier with RBF kernel\n",
    "        self.classifier.fit(self.X_train, self.y_train)  # Train the classifier\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def perform_logistic_regression(self):\n",
    "        self.classifier = LogisticRegression(random_state=42, class_weight=self.class_weight)  # Initialize the Logistic Regression Classifier\n",
    "        self.classifier.fit(self.X_train, self.y_train)  # Train the classifier\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def perform_neural_network(self):\n",
    "        # self.classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, random_state=42)  # Initialize the MLP Classifier with one hidden layer of 100 neurons\n",
    "        input_dim = len(self.X_train.values[0])\n",
    "        custom_mlp = CustomMLPClassifier(max_iter=100, random_state=42, class_weight=self.class_weight, input_dim=input_dim)\n",
    "        custom_mlp.compile_model()  # You may need to pass additional parameters here depending on your requirements\n",
    "        self.classifier = custom_mlp\n",
    "        self.classifier.fit(self.X_train, self.y_train)  # Train the classifier\n",
    "        y_pred = self.classifier.predict(self.X_cv)  # Perform prediction on the cross-validation set\n",
    "        self.ac_cv = accuracy_score(self.y_cv, y_pred)  # Calculate accuracy\n",
    "        return self.ac_cv\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        y_pred_final = self.classifier.predict(self.X_test_final)\n",
    "        print(\"kkk\", 1 in y_pred_final)\n",
    "        print(\"lll\", 0 in y_pred_final)\n",
    "        self.ac_final = accuracy_score(self.y_test_final,y_pred_final)\n",
    "        return self.ac_final, self.y_test_final, y_pred_final\n",
    "\n",
    "class Master:\n",
    "    def __init__(self, balance_weights = True, algo = \"knn\"):\n",
    "        self.results = {}\n",
    "        self.balance_weights = balance_weights\n",
    "        self.algo = algo\n",
    "\n",
    "    def print_classification_report(self, y_true, y_pred):\n",
    "        report = classification_report(y_true, y_pred, target_names=['Negative Class', 'Positive Class'], output_dict=True)\n",
    "        print(\"{:<20} {:<15} {:<15} {:<15} {:<15}\".format('', 'precision', 'recall', 'f1-score', 'support'))\n",
    "        for class_name, metrics in report.items():\n",
    "            if class_name in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                continue\n",
    "            print(\"{:<20} {:<15.2f} {:<15.2f} {:<15.2f} {:<15}\".format(class_name,\n",
    "                                                                       metrics['precision'],\n",
    "                                                                       metrics['recall'],\n",
    "                                                                       metrics['f1-score'],\n",
    "                                                                       metrics['support']))\n",
    "        \n",
    "    def organize_results(self):\n",
    "        items = []\n",
    "        for k, v in self.results.items():\n",
    "            print(k, v)\n",
    "            if isinstance(v, dict):\n",
    "                for xk, xv in v.items():\n",
    "                    new_x_key = xk\n",
    "                    items.append((new_x_key, xv))\n",
    "            else:\n",
    "                new_key = k\n",
    "                items.append((new_key, v))\n",
    "        r_items = dict(items)\n",
    "        df = pd.DataFrame({'method': list(r_items.keys()), 'result': list(r_items.values())})\n",
    "        return df\n",
    "\n",
    "    def run_without_cv(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_without_cv()\n",
    "        rslts, y_pred = anlyzr.perform_without_cv()\n",
    "        self.results[\"run without cv\"] = rslts\n",
    "        self.print_classification_report(anlyzr.y_test_final, y_pred)\n",
    "\n",
    "    def run_with_cv(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        \n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"knn\":\n",
    "            anlyzr.perform_knn()\n",
    "        elif self.algo == \"rf\":\n",
    "            anlyzr.perform_random_forest()\n",
    "        elif self.algo == \"svm\":\n",
    "            anlyzr.perform_svm()\n",
    "        elif self.algo == \"logreg\":\n",
    "            anlyzr.perform_logistic_regression()\n",
    "        elif self.algo == \"nn\":\n",
    "            anlyzr.perform_neural_network()\n",
    "        self.results[\"run with cv\"], y_test_final, y_pred_final = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_kfold(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        (best_avg_score, scores) = anlyzr.perform_kfold_cv()\n",
    "        rslt, y_test_final, y_pred_final =  anlyzr.get_accuracy()\n",
    "        self.results[\"after_k_fold_run\"] = {\n",
    "            \"best kfold cv score\": best_avg_score,\n",
    "            \"scores\": scores,\n",
    "            \"final kfold score on test dataset\": rslt\n",
    "        }\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_filter(self):\n",
    "        # Implement feature selection using filter method (e.g., correlation)\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.perform_filter_methods()\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"knn\":\n",
    "            anlyzr.perform_knn()\n",
    "        elif self.algo == \"rf\":\n",
    "            anlyzr.perform_random_forest()\n",
    "        elif self.algo == \"svm\":\n",
    "            anlyzr.perform_svm()\n",
    "        elif self.algo == \"logreg\":\n",
    "            anlyzr.perform_logistic_regression()\n",
    "        elif self.algo == \"nn\":\n",
    "            anlyzr.perform_neural_network()\n",
    "        self.results[\"with_filter_method\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "\n",
    "    def run_with_wrapper(self):\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        self.results = anlyzr.perform_wrapper_method()\n",
    "        anlyzr.plot_wrapper_scores()\n",
    "\n",
    "    def run_with_pca(self):\n",
    "        # Implement feature selection using PCA\n",
    "        anlyzr = DataAnalyzer(balance_weights=self.balance_weights, algo=self.algo)\n",
    "        anlyzr.get_x_and_Y()\n",
    "        anlyzr.perform_pca(n_components=2)\n",
    "        anlyzr.perform_manual_splitting_cv()\n",
    "        if self.algo == \"knn\":\n",
    "            anlyzr.perform_knn()\n",
    "        elif self.algo == \"rf\":\n",
    "            anlyzr.perform_random_forest()\n",
    "        elif self.algo == \"svm\":\n",
    "            anlyzr.perform_svm()\n",
    "        elif self.algo == \"logreg\":\n",
    "            anlyzr.perform_logistic_regression()\n",
    "        elif self.algo == \"nn\":\n",
    "            anlyzr.perform_neural_network()\n",
    "        self.results[\"with_pca\"], y_test_final, y_pred_final  = anlyzr.get_accuracy()\n",
    "        self.print_classification_report(y_test_final, y_pred_final)\n",
    "    \n",
    "    def run_cv_problem(self):\n",
    "        self.run_without_cv()\n",
    "        self.run_with_cv()\n",
    "        self.run_with_kfold()\n",
    "        return self.results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.82            0.94            0.87            4666.0         \n",
      "Positive Class       0.56            0.29            0.38            1334.0         \n",
      "with_pca 0.7918333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.791833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.791833"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"knn\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.82            0.92            0.87            4666.0         \n",
      "Positive Class       0.53            0.30            0.39            1334.0         \n",
      "with_pca 0.786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method  result\n",
       "0  with_pca   0.786"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"rf\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.86            0.85            0.86            4666.0         \n",
      "Positive Class       0.50            0.50            0.50            1334.0         \n",
      "with_pca 0.7755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method  result\n",
       "0  with_pca  0.7755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"svm\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.86            0.64            0.73            4666.0         \n",
      "Positive Class       0.33            0.64            0.44            1334.0         \n",
      "with_pca 0.6368333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.636833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method    result\n",
       "0  with_pca  0.636833"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"logreg\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5977 - loss: 173291.4531 - val_accuracy: 0.3322 - val_loss: 57277.9453\n",
      "Epoch 3/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5834 - loss: 78275.3281 - val_accuracy: 0.6272 - val_loss: 33029.3398\n",
      "Epoch 4/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4388 - loss: 37145.3867 - val_accuracy: 0.7772 - val_loss: 159748.6406\n",
      "Epoch 5/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5365 - loss: 51519.6914 - val_accuracy: 0.7644 - val_loss: 88531.9609\n",
      "Epoch 6/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5654 - loss: 45043.7852 - val_accuracy: 0.6039 - val_loss: 53208.0000\n",
      "Epoch 7/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5027 - loss: 29864.2129 - val_accuracy: 0.3711 - val_loss: 25284.5996\n",
      "Epoch 8/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3564 - loss: 15056.4131 - val_accuracy: 0.7683 - val_loss: 61556.0430\n",
      "Epoch 9/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5636 - loss: 42499.4375 - val_accuracy: 0.6389 - val_loss: 32359.6582\n",
      "Epoch 10/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5906 - loss: 31700.1426 - val_accuracy: 0.7611 - val_loss: 60743.7539\n",
      "Epoch 11/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4890 - loss: 26162.4258 - val_accuracy: 0.6667 - val_loss: 52591.1172\n",
      "Epoch 12/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5329 - loss: 26376.9824 - val_accuracy: 0.7678 - val_loss: 49045.0586\n",
      "Epoch 13/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6071 - loss: 27647.8262 - val_accuracy: 0.6883 - val_loss: 22218.9883\n",
      "Epoch 14/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6068 - loss: 20787.9902 - val_accuracy: 0.7417 - val_loss: 35016.0430\n",
      "Epoch 15/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6328 - loss: 23436.3125 - val_accuracy: 0.6983 - val_loss: 21801.8555\n",
      "Epoch 16/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5223 - loss: 17973.4766 - val_accuracy: 0.6706 - val_loss: 19754.8984\n",
      "Epoch 17/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4406 - loss: 12954.6807 - val_accuracy: 0.6417 - val_loss: 16977.6953\n",
      "Epoch 18/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5153 - loss: 15690.1572 - val_accuracy: 0.7233 - val_loss: 28828.7969\n",
      "Epoch 19/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6222 - loss: 20714.2520 - val_accuracy: 0.6744 - val_loss: 20609.1641\n",
      "Epoch 20/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6117 - loss: 15390.6748 - val_accuracy: 0.6472 - val_loss: 13975.0996\n",
      "Epoch 21/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6382 - loss: 15214.9131 - val_accuracy: 0.7689 - val_loss: 31675.5391\n",
      "Epoch 22/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6666 - loss: 15047.3135 - val_accuracy: 0.7233 - val_loss: 17557.8750\n",
      "Epoch 23/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6224 - loss: 13174.3535 - val_accuracy: 0.7650 - val_loss: 26159.4355\n",
      "Epoch 24/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6527 - loss: 13275.6357 - val_accuracy: 0.6850 - val_loss: 13009.9941\n",
      "Epoch 25/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6693 - loss: 11870.0381 - val_accuracy: 0.7467 - val_loss: 15337.1953\n",
      "Epoch 26/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 10587.9668 - val_accuracy: 0.7739 - val_loss: 26921.6621\n",
      "Epoch 27/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6675 - loss: 11066.7598 - val_accuracy: 0.7083 - val_loss: 12001.8711\n",
      "Epoch 28/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6389 - loss: 9091.8252 - val_accuracy: 0.6450 - val_loss: 9492.6465\n",
      "Epoch 29/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6682 - loss: 8193.6553 - val_accuracy: 0.6933 - val_loss: 10722.2012\n",
      "Epoch 30/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5851 - loss: 9955.4707 - val_accuracy: 0.7539 - val_loss: 11976.8096\n",
      "Epoch 31/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6768 - loss: 8676.4482 - val_accuracy: 0.7472 - val_loss: 10796.8682\n",
      "Epoch 32/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6768 - loss: 7240.5039 - val_accuracy: 0.7189 - val_loss: 8758.3125\n",
      "Epoch 33/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6787 - loss: 6860.6792 - val_accuracy: 0.6539 - val_loss: 9595.5381\n",
      "Epoch 34/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6747 - loss: 6547.2588 - val_accuracy: 0.5794 - val_loss: 9866.3096\n",
      "Epoch 35/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6850 - loss: 5399.1123 - val_accuracy: 0.6067 - val_loss: 8992.4082\n",
      "Epoch 36/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6853 - loss: 5098.3198 - val_accuracy: 0.7511 - val_loss: 9849.1699\n",
      "Epoch 37/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6857 - loss: 4723.6724 - val_accuracy: 0.7172 - val_loss: 8534.0322\n",
      "Epoch 38/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6831 - loss: 4804.6362 - val_accuracy: 0.5328 - val_loss: 7098.2231\n",
      "Epoch 39/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6872 - loss: 4450.1479 - val_accuracy: 0.7494 - val_loss: 8653.8838\n",
      "Epoch 40/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6801 - loss: 4079.9570 - val_accuracy: 0.6767 - val_loss: 5353.3721\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.82            0.76            0.79            4666.0         \n",
      "Positive Class       0.33            0.41            0.37            1334.0         \n",
      "run with cv 0.6853333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run with cv</td>\n",
       "      <td>0.685333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method    result\n",
       "0  run with cv  0.685333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"nn\")\n",
    "filter_mstr.run_with_cv()\n",
    "filter_mstr.organize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirbilal/Desktop/ASSGNS_MLL/assgn_3/assgn_3_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7508 - loss: 362.0458 - val_accuracy: 0.8106 - val_loss: 314.1719\n",
      "Epoch 3/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8035 - loss: 307.5367 - val_accuracy: 0.8111 - val_loss: 305.2805\n",
      "Epoch 4/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8032 - loss: 302.1535 - val_accuracy: 0.8083 - val_loss: 303.3139\n",
      "Epoch 5/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8036 - loss: 301.2557 - val_accuracy: 0.8089 - val_loss: 302.6328\n",
      "Epoch 6/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 300.8263 - val_accuracy: 0.8094 - val_loss: 302.4312\n",
      "Epoch 7/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 300.5564 - val_accuracy: 0.8078 - val_loss: 302.3050\n",
      "Epoch 8/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 300.3409 - val_accuracy: 0.8083 - val_loss: 302.2118\n",
      "Epoch 9/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8038 - loss: 300.1708 - val_accuracy: 0.8094 - val_loss: 302.1436\n",
      "Epoch 10/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 300.0612 - val_accuracy: 0.8094 - val_loss: 302.1102\n",
      "Epoch 11/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 299.9297 - val_accuracy: 0.8089 - val_loss: 302.0881\n",
      "Epoch 12/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 299.8476 - val_accuracy: 0.8078 - val_loss: 302.1558\n",
      "Epoch 13/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8038 - loss: 299.7820 - val_accuracy: 0.8083 - val_loss: 302.1333\n",
      "Epoch 14/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 299.7097 - val_accuracy: 0.8078 - val_loss: 302.3045\n",
      "Epoch 15/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 299.6518 - val_accuracy: 0.8078 - val_loss: 302.4044\n",
      "Epoch 16/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 299.5445 - val_accuracy: 0.8072 - val_loss: 302.3322\n",
      "Epoch 17/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 299.4914 - val_accuracy: 0.8083 - val_loss: 302.4608\n",
      "Epoch 18/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 299.4256 - val_accuracy: 0.8083 - val_loss: 302.4592\n",
      "Epoch 19/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 299.3916 - val_accuracy: 0.8089 - val_loss: 302.4876\n",
      "Epoch 20/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 299.3708 - val_accuracy: 0.8089 - val_loss: 302.5138\n",
      "Epoch 21/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 299.3110 - val_accuracy: 0.8083 - val_loss: 302.4489\n",
      "Epoch 22/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 299.2499 - val_accuracy: 0.8089 - val_loss: 302.4211\n",
      "Epoch 23/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 299.1860 - val_accuracy: 0.8089 - val_loss: 302.4434\n",
      "Epoch 24/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 299.1456 - val_accuracy: 0.8089 - val_loss: 302.4947\n",
      "Epoch 25/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 299.1169 - val_accuracy: 0.8089 - val_loss: 302.4230\n",
      "Epoch 26/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 299.0709 - val_accuracy: 0.8089 - val_loss: 302.4372\n",
      "Epoch 27/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 299.0522 - val_accuracy: 0.8100 - val_loss: 302.4927\n",
      "Epoch 28/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 299.0167 - val_accuracy: 0.8106 - val_loss: 302.5541\n",
      "Epoch 29/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8043 - loss: 298.9975 - val_accuracy: 0.8100 - val_loss: 302.5355\n",
      "Epoch 30/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8044 - loss: 298.9455 - val_accuracy: 0.8100 - val_loss: 302.5618\n",
      "Epoch 31/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 298.9221 - val_accuracy: 0.8100 - val_loss: 302.6332\n",
      "Epoch 32/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 298.9051 - val_accuracy: 0.8094 - val_loss: 302.5757\n",
      "Epoch 33/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 298.8906 - val_accuracy: 0.8100 - val_loss: 302.6079\n",
      "Epoch 34/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 298.8607 - val_accuracy: 0.8094 - val_loss: 302.5226\n",
      "Epoch 35/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 298.8145 - val_accuracy: 0.8094 - val_loss: 302.5882\n",
      "Epoch 36/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 298.7847 - val_accuracy: 0.8100 - val_loss: 302.6112\n",
      "Epoch 37/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 298.7874 - val_accuracy: 0.8100 - val_loss: 302.5479\n",
      "Epoch 38/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 298.7605 - val_accuracy: 0.8094 - val_loss: 302.5768\n",
      "Epoch 39/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 298.7576 - val_accuracy: 0.8100 - val_loss: 302.5848\n",
      "Epoch 40/40\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 298.7340 - val_accuracy: 0.8100 - val_loss: 302.6396\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step\n",
      "kkk True\n",
      "lll True\n",
      "                     precision       recall          f1-score        support        \n",
      "Negative Class       0.83            0.95            0.88            4666.0         \n",
      "Positive Class       0.64            0.32            0.43            1334.0         \n",
      "with_pca 0.808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_pca</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method  result\n",
       "0  with_pca   0.808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_mstr = Master(balance_weights=True, algo=\"nn\")\n",
    "filter_mstr.run_with_pca()\n",
    "filter_mstr.organize_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assgn_3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
